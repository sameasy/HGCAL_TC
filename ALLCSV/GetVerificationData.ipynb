{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import numba\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encode import encode, decode\n",
    "\n",
    "encodeList = np.vectorize(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getElinkInput(df):\n",
    "    linkData = []\n",
    "    for i in range(12):\n",
    "        thislinkData = ''\n",
    "        for j in range(4):\n",
    "            val = df[(df.eLink==i) & (df.eLinkChannel==j)].encodedCharge.values\n",
    "            if len(val)==0:\n",
    "                thislinkData += '0000000'\n",
    "            else:\n",
    "                thislinkData += format(int(val[0]), '#0%ib'%(9))[2:]\n",
    "        linkData.append(thislinkData)\n",
    "    return linkData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###NEEDS TO BE UPDATED TO USE CSV OUTPUTS\n",
    "def getAlgoBlockOutputBestChoice(df, nTC, sumEncoding=(0,4,4)):\n",
    "    SUM = encode(df.calibCharge.sum().astype(np.int),sumEncoding[0], sumEncoding[1], sumEncoding[2],asInt=True)\n",
    "    TOPNCHARGE = (df.nlargest(nTC,'calibCharge'))\n",
    "    selidx = TOPNCHARGE.index\n",
    "    noselidx = list(set(df.index)^set(TOPNCHARGE.index))\n",
    "    df = df.copy(deep=True)\n",
    "    df.iloc[noselidx, df.columns.get_loc('calibCharge')] = 0\n",
    "    ADD_MAP = (df.calibCharge>0).values.astype(np.int)\n",
    "    CHARGES = [x for x in df.calibCharge if x != 0]\n",
    "#    print (ADD_MAP,CHARGES)\n",
    "    return (ADD_MAP,CHARGES,SUM)\n",
    "\n",
    "\n",
    "def getAlgoBlockOutputThreshold(tc_Charge, thresholds = np.array([0]*48), sumEncoding=(0,5,3), tcEncoding=(0,4,4)):\n",
    "    MOD_SUM_0 = encode(tc_Charge[0:16].sum(),sumEncoding[0], sumEncoding[1], sumEncoding[2],asInt=True)\n",
    "    MOD_SUM_1 = encode(tc_Charge[16:32].sum(),sumEncoding[0], sumEncoding[1], sumEncoding[2],asInt=True)\n",
    "    MOD_SUM_2 = encode(tc_Charge[32:48].sum(),sumEncoding[0], sumEncoding[1], sumEncoding[2],asInt=True)\n",
    "\n",
    "    SUM = encode(tc_Charge.sum(),sumEncoding[0], sumEncoding[1], sumEncoding[2],asInt=True)\n",
    "    pass_threshold = tc_Charge >= thresholds    \n",
    "    NTCQ = pass_threshold.sum()\n",
    "    ADD_MAP = pass_threshold\n",
    "    ADD_MAP.dtype=np.int8\n",
    "    \n",
    "    CHARGEQ = encodeList(tc_Charge[pass_threshold],tcEncoding[0], tcEncoding[1],tcEncoding[2], False,True)\n",
    "\n",
    "    return (NTCQ, ADD_MAP, CHARGEQ,SUM,MOD_SUM_0,MOD_SUM_1,MOD_SUM_2)\n",
    "\n",
    "\n",
    "\n",
    "def bitmapArrayToInt(bitmap):\n",
    "    total = 0\n",
    "    for i in range(len(bitmap)):\n",
    "        total += bitmap[i]<<i\n",
    "    return total, format(total, '#0%ib'%(len(bitmap)+2))[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatThresholdOutput(BC, NTCQ, ADD_MAP, CHARGEQ,SUM,MOD_SUM_0,MOD_SUM_1,MOD_SUM_2):\n",
    "    header = format(BC, '#0%ib'%(15))[-5:]\n",
    "    dataType = ''\n",
    "    if NTCQ==0: \n",
    "        dataType='000'\n",
    "    elif NTCQ<8:\n",
    "        dataType='001'\n",
    "    else:\n",
    "        dataType='010'\n",
    "    modSumData = format(SUM, '#0%ib'%(10))[2:]\n",
    "    extraBit=''\n",
    "    if NTCQ==0:\n",
    "        nChannelData=''\n",
    "        AddressMapData=''\n",
    "        ChargeData=''\n",
    "    elif NTCQ<8:\n",
    "        nChannelData=format(NTCQ, '#0%ib'%(3+2))[2:]\n",
    "        \n",
    "        bitmap = np.array([int(x) for x in format(ADD_MAP, '#0%ib'%(48+2))[2:]][::-1])\n",
    "        channelNumbers = np.arange(48)[bitmap==1]\n",
    "        channelNumbersBin = [format(x,'#0%ib'%(6+2))[2:] for x in channelNumbers]\n",
    "        AddressMapData = ''\n",
    "        for x in channelNumbersBin: AddressMapData += x\n",
    "        \n",
    "        ChargeData = ''\n",
    "        for x in CHARGEQ:\n",
    "            ChargeData+=format(x, '#0%ib'%(9))[2:]\n",
    "        \n",
    "    else:\n",
    "        nChannelData=''\n",
    "        AddressMapData=format(ADD_MAP, '#0%ib'%(48+2))[2:]\n",
    "        ChargeData = ''\n",
    "        for x in CHARGEQ:\n",
    "            ChargeData+=format(x, '#0%ib'%(9))[2:]\n",
    "\n",
    "    formattedData = header + dataType + modSumData + extraBit + nChannelData + AddressMapData + ChargeData\n",
    "    if len(formattedData)%16==0:\n",
    "        nPadBits=0\n",
    "        paddedData = formattedData\n",
    "    else:\n",
    "        nPadBits = 16 - (len(formattedData)%16)\n",
    "        paddedData = formattedData + '0'*nPadBits\n",
    "\n",
    "#    print(NTCQ,nPadBits)\n",
    "    \n",
    "    return paddedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatThresholdOutput_Truncated1(BC, NTCQ, ADD_MAP, CHARGEQ,SUM,MOD_SUM_0,MOD_SUM_1,MOD_SUM_2):\n",
    "    header = format(BC, '#0%ib'%(15))[-5:]\n",
    "    dataType = '110'\n",
    "    modSumData = format(SUM, '#0%ib'%(10))[2:]\n",
    "\n",
    "    formattedData = header + dataType + modSumData\n",
    "    return formattedData\n",
    "\n",
    "def formatThresholdOutput_Truncated2(BC, NTCQ, ADD_MAP, CHARGEQ,SUM,MOD_SUM_0,MOD_SUM_1,MOD_SUM_2):\n",
    "    header = format(BC, '#0%ib'%(15))[-5:]\n",
    "    dataType = '110'\n",
    "    modSumData = format(MOD_SUM_0, '#0%ib'%(10))[2:] + format(MOD_SUM_1, '#0%ib'%(10))[2:] + format(MOD_SUM_2, '#0%ib'%(10))[2:]\n",
    "\n",
    "    formattedData = header + dataType + modSumData\n",
    "    return formattedData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibRegToCorr(register):\n",
    "    ### bits\n",
    "    ### 5,    4,    3,    2,    1,    0\n",
    "    ### 1,  1/2,  1/4,  1/8, 1/16, 1/32\n",
    "\n",
    "    corr = 0.\n",
    "    corr += 1./32 * (register>>0&1)\n",
    "    corr += 1./16 * (register>>1&1)\n",
    "    corr += 1./8  * (register>>2&1)\n",
    "    corr += 1./4  * (register>>3&1)\n",
    "    corr += 1./2  * (register>>4&1)\n",
    "    corr +=  1.   * (register>>5&1)\n",
    "#    corr = 1. + corr\n",
    "    return corr\n",
    "calibRegToCorr = np.vectorize(calibRegToCorr)\n",
    "\n",
    "calibRegisters = np.ones(48).astype(np.int)\n",
    "calibRegisters = np.random.choice([28,29,30,31,32,33,34,35,36,37],48)\n",
    "\n",
    "corrFactor= calibRegToCorr(calibRegisters)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Selection of a single wafer\n",
    "subdet=3\n",
    "layer=5\n",
    "wafer = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcmapCSVname = 'TC_ELINK_MAP.csv'\n",
    "df_tcmap = pd.read_csv(tcmapCSVname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName='root://cmseos.fnal.gov//store/user/dnoonan/HGCAL_Concentrator/NewNtuples/ntuple_hgcalNtuples_vbf_hmm_200PU_1.root'\n",
    "_tree = uproot.open(fName,xrootdsource=dict(chunkbytes=1024**3, limitbytes=1024**3))['hgcalTriggerNtuplizer/HGCalTriggerNtuple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe\n",
    "#df = _tree.pandas.df( ['tc_subdet','tc_zside','tc_layer','tc_wafer','tc_cell','tc_uncompressedCharge','tc_compressedCharge','tc_data','tc_mipPt'],entrystart=0,entrystop=25)\n",
    "df = _tree.pandas.df( ['tc_subdet','tc_zside','tc_layer','tc_wafer','tc_cell','tc_uncompressedCharge','tc_compressedCharge','tc_data','tc_mipPt'])\n",
    "df.columns = ['subdet','zside','layer','wafer','triggercell','uncompressedCharge','compressedCharge','data','mipPt']\n",
    "\n",
    "#remove unwanted layers\n",
    "df = df[(df.subdet==subdet) & (df.layer==layer) & (df.wafer==wafer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index\n",
    "df.set_index(['subdet','zside','layer','wafer','triggercell'],append=True,inplace=True)\n",
    "df.reset_index('subentry',drop=True,inplace=True)\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split +/- zside into separate entries\n",
    "df.reset_index(inplace=True)\n",
    "maxN = df.entry.max()\n",
    "df.set_index(['zside'],inplace=True)\n",
    "\n",
    "df.loc[-1,['entry']] = df.loc[-1,['entry']] + maxN+1\n",
    "df.reset_index(inplace=True)\n",
    "df.set_index(['entry','subdet','zside','layer','wafer','triggercell'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get geometry information\n",
    "geomName = \"root://cmseos.fnal.gov//store/user/dnoonan/HGCAL_Concentrator/triggerGeomV9.root\"\n",
    "geomTree = uproot.open(geomName,xrootdsource=dict(chunkbytes=1024**3, limitbytes=1024**3))[\"hgcaltriggergeomtester/TreeTriggerCells\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geomDF = geomTree.pandas.df(['subdet','zside','layer','wafer','triggercell','x','y','z','c_n'])\n",
    "geomDF['r'] = (geomDF['x']**2 + geomDF['y']**2)**.5\n",
    "geomDF['eta'] = np.arcsinh(geomDF.z/geomDF.r)\n",
    "geomDF.set_index(['subdet','zside','layer','wafer','triggercell'],inplace=True)\n",
    "geomDF['isHDM'] = geomDF.c_n>4\n",
    "geomDF.sort_index(inplace=True)\n",
    "geomDF.drop(['x','y','c_n'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Need to update layer list in geomdf for subdet 4 and 5 to match df\n",
    "geomDF.reset_index(inplace=True)\n",
    "geomDF.loc[geomDF.subdet==4,'layer'] += 28\n",
    "geomDF.loc[geomDF.subdet==5,'layer'] += 28\n",
    "geomDF.set_index(['subdet','zside','layer','wafer','triggercell'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_mipPt = 1.35\n",
    "fCtoADC = 100./1024.\n",
    "geomDF['threshold_fC'] = threshold_mipPt*np.cosh(geomDF.eta) *3.43\n",
    "geomDF['threshold_ADC'] = np.round(geomDF.threshold_fC/fCtoADC).astype(np.int)\n",
    "#geomDF['threshold_ADC'] = geomDF.threshold_fC/fCtoADC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index('entry',inplace=True)\n",
    "\n",
    "df['isHDM'] = geomDF['isHDM']\n",
    "# df['eta'] = geomDF['eta']\n",
    "df['threshold_ADC'] = geomDF['threshold_ADC']\n",
    "#df['threshold_ADC_int'] = geomDF['threshold_ADC_int']\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.set_index(['entry','subdet','zside','layer','wafer','triggercell'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nExp = 4\n",
    "nMant = 3\n",
    "nDropHDM = 3\n",
    "nDropLDM = 1\n",
    "roundBits = False\n",
    "\n",
    "df['encodedCharge'] = np.where(df.isHDM,df.uncompressedCharge.apply(encode,args=(nDropHDM,nExp,nMant,roundBits,True)),df.uncompressedCharge.apply(encode,args=(nDropLDM,nExp,nMant,roundBits,True)))\n",
    "df['decodedCharge'] = np.where(df.isHDM,df.encodedCharge.apply(decode,args=(nDropHDM,nExp,nMant)),df.encodedCharge.apply(decode,args=(nDropLDM,nExp,nMant)))\n",
    "df['pass_135'] = df.decodedCharge>df.threshold_ADC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index('zside',drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleEvent = geomDF.reset_index()\n",
    "singleEvent = singleEvent[(singleEvent.subdet==subdet) & (singleEvent.zside==1) & (singleEvent.layer==layer) & (singleEvent.wafer==wafer)]\n",
    "#geomDF = geomDF[(geomDF.subdet==subdet) & (geomDF.zside==1) & (geomDF.layer==layer) & (geomDF.wafer==wafer)]\n",
    "singleEvent.set_index(['subdet','layer','wafer','triggercell'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#singleEvent.reset_index(inplace=True)\n",
    "singleEvent = singleEvent.reset_index().merge(df_tcmap, on=['triggercell', 'isHDM']).set_index(['subdet','layer','wafer','triggercell'])\n",
    "#singleEvent.set_index(['subdet','layer','wafer','triggercell'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Input csv\n",
    "inputLines = \"OrbitNumber, BX, \"\n",
    "for i in range(12):\n",
    "    inputLines += \"ePortRxDataGroup_%i, \"%i\n",
    "for i in range(48):\n",
    "    inputLines += \"F2F_%i, \"%i\n",
    "for i in range(48):\n",
    "    inputLines += \"CALQ_%i, \"%i\n",
    "\n",
    "inputLines = inputLines[:-2]+\"\\n\"\n",
    "\n",
    "eventList = df.reset_index().entry.unique()\n",
    "eventTracker = []\n",
    "\n",
    "for eNum in range(100):\n",
    "    event = np.random.choice(eventList)\n",
    "    eventTracker.append(event)\n",
    "\n",
    "    OrbitNumber = int(eNum/3564)\n",
    "    BX = eNum % 3564\n",
    "    \n",
    "    singleEvent['encodedCharge'] = df.loc[event]['encodedCharge']\n",
    "    singleEvent['decodedCharge'] = df.loc[event]['decodedCharge']\n",
    "    singleEvent.encodedCharge.fillna(0,inplace=True)\n",
    "    singleEvent.decodedCharge.fillna(0,inplace=True)\n",
    "\n",
    "    singleEvent['calibCharge'] = (singleEvent.decodedCharge * corrFactor).round().astype(np.int)\n",
    "    singleEvent['calibCharge_Encoded'] = np.where(singleEvent.isHDM,singleEvent.calibCharge.apply(encode,args=(nDropHDM,nExp,nMant,True,True)),singleEvent.calibCharge.apply(encode,args=(nDropLDM,nExp,nMant,True,True)))\n",
    "    singleEvent['pass_135'] = singleEvent.calibCharge>=singleEvent.threshold_ADC\n",
    "    \n",
    "    inputLines += \"%i, %i, \"%(OrbitNumber, BX)\n",
    "    \n",
    "    for x in getElinkInput(singleEvent):\n",
    "        inputLines += \"%s, \"%x\n",
    "\n",
    "    for x in singleEvent.decodedCharge.values:\n",
    "        inputLines += \"%i, \"%x\n",
    "\n",
    "    for x in singleEvent.calibCharge.values:\n",
    "        inputLines += \"%i, \"%x\n",
    "    inputLines = inputLines[:-2]+\"\\n\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CSV_Files/Test1/Inputs.csv','w') as _file:\n",
    "    _file.write(inputLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algoInputData = pd.read_csv('CSV_Files/Test1/Inputs.csv',index_col=['OrbitNumber','BX'],skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in algoInputData.columns.tolist() if 'CALQ' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcCharge = algoInputData[cols].loc[0,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcCharge[0:16].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = singleEvent.threshold_ADC.values\n",
    "isHDM = singleEvent.isHDM.any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passThresh = tcCharge > thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcEncoding = (3,4,3) if isHDM else (1,4,3)\n",
    "vals = getAlgoBlockOutputThreshold(tcCharge, thresholds, sumEncoding=(0,5,3),tcEncoding=tcEncoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals[1].dtype=np.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode(930,1,4,3,False,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eLinkInputLines = \"BC, \"\n",
    "\n",
    "calibInputLines = \"BC, \"\n",
    "\n",
    "algoInputLines = \"BC, \"\n",
    "\n",
    "algoOutputLines = \"\"\n",
    "algoOutputLines += \"BC, NTCQ, ADD_MAP, \"\n",
    "\n",
    "for i in range(12):\n",
    "    eLinkInputLines += \"ePortRxDataGroup_%i, \"%i\n",
    "for i in range(48):\n",
    "    calibInputLines += \"SM_%i, \"%i\n",
    "    algoInputLines += \"CALQ_%i, \"%i\n",
    "    algoOutputLines += \"CHARGEQ_%i, \"%i\n",
    "\n",
    "eLinkInputLines = eLinkInputLines[:-2]+\"\\n\"\n",
    "\n",
    "calibInputLines = calibInputLines[:-2]+\"\\n\"\n",
    "algoInputLines = algoInputLines[:-2]+\"\\n\"\n",
    "algoOutputLines+=\"SUM, MOD_SUM_0, MOD_SUM_1, MOD_SUM_2\\n\"\n",
    "\n",
    "formattedDataLines = 'BC, DATAHEX, DATA\\n'\n",
    "formattedDataLines_Truncated1 = 'BC, DATAHEX, DATA\\n'\n",
    "formattedDataLines_Truncated2 = 'BC, DATAHEX, DATA\\n'\n",
    "\n",
    "eventList = df.reset_index().entry.unique()\n",
    "eventTracker = []\n",
    "\n",
    "for BC in range(100):\n",
    "    event = np.random.choice(eventList)\n",
    "    eventTracker.append(event)\n",
    "\n",
    "    singleEvent['encodedCharge'] = df.loc[event]['encodedCharge']\n",
    "    singleEvent['decodedCharge'] = df.loc[event]['decodedCharge']\n",
    "    singleEvent.encodedCharge.fillna(0,inplace=True)\n",
    "    singleEvent.decodedCharge.fillna(0,inplace=True)\n",
    "\n",
    "    singleEvent['calibCharge'] = (singleEvent.decodedCharge * corrFactor).round().astype(np.int)\n",
    "    singleEvent['calibCharge_Encoded'] = np.where(singleEvent.isHDM,singleEvent.calibCharge.apply(encode,args=(nDropHDM,nExp,nMant,True,True)),singleEvent.calibCharge.apply(encode,args=(nDropLDM,nExp,nMant,True,True)))\n",
    "    singleEvent['pass_135'] = singleEvent.calibCharge>=singleEvent.threshold_ADC\n",
    "    \n",
    "    \n",
    "    \n",
    "    eLinkInputLines += \"%i, \"%BC\n",
    "    calibInputLines += \"%i, \"%BC\n",
    "    algoInputLines += \"%i, \"%BC\n",
    "    algoOutputLines += \"%i, \"%BC\n",
    "    formattedDataLines += \"%i, \"%BC\n",
    "    formattedDataLines_Truncated1 += \"%i, \"%BC\n",
    "    formattedDataLines_Truncated2 += \"%i, \"%BC\n",
    "\n",
    "    for x in getElinkInput(singleEvent):\n",
    "        eLinkInputLines += \"%s, \"%x\n",
    "    eLinkInputLines = eLinkInputLines[:-2]+\"\\n\"\n",
    "    \n",
    "    for x in singleEvent.decodedCharge.values:\n",
    "        calibInputLines += \"%i, \"%x\n",
    "    calibInputLines = calibInputLines[:-2]+\"\\n\"\n",
    "\n",
    "    for x in singleEvent.calibCharge.values:\n",
    "        algoInputLines += \"%i, \"%x\n",
    "    algoInputLines = algoInputLines[:-2]+\"\\n\"\n",
    "    \n",
    "    NTCQ, ADD_MAP, CHARGEQ,SUM,MOD_SUM_0,MOD_SUM_1,MOD_SUM_2 = getAlgoBlockOutputThreshold(singleEvent.reset_index(['subdet','layer','wafer'],drop=True))\n",
    "    ADD_MAP_INT = bitmapArrayToInt(ADD_MAP)[0]\n",
    "    algoOutputLines += \"%i, %i, \"%(NTCQ, ADD_MAP_INT)\n",
    "    for x in CHARGEQ:\n",
    "        algoOutputLines += \"%i, \"%x\n",
    "    for i in range(48-len(CHARGEQ)):\n",
    "        algoOutputLines += \"0, \"\n",
    "    algoOutputLines += \"%i, %i, %i, %i\\n\"%( SUM, MOD_SUM_0, MOD_SUM_1, MOD_SUM_2)\n",
    "\n",
    "    data = formatThresholdOutput(BC, NTCQ, ADD_MAP_INT, CHARGEQ,SUM,MOD_SUM_0,MOD_SUM_1,MOD_SUM_2)\n",
    "    dataTruncated1 = formatThresholdOutput_Truncated1(BC, NTCQ, ADD_MAP_INT, CHARGEQ,SUM,MOD_SUM_0,MOD_SUM_1,MOD_SUM_2)\n",
    "    dataTruncated2 = formatThresholdOutput_Truncated2(BC, NTCQ, ADD_MAP_INT, CHARGEQ,SUM,MOD_SUM_0,MOD_SUM_1,MOD_SUM_2)\n",
    "    \n",
    "    formattedDataLines += format(int(data,2), '#0%ix'%(len(data)/4+2)) + \", \"+data+\"\\n\"\n",
    "    formattedDataLines_Truncated1 += format(int(dataTruncated1,2), '#0%ix'%(len(dataTruncated1)/4+2)) + \", \"+dataTruncated1+\"\\n\"\n",
    "    formattedDataLines_Truncated2 += format(int(dataTruncated2,2), '#0%ix'%(len(dataTruncated2)/4+2)) + \", \"+dataTruncated2+\"\\n\"\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CSV_Files/eLinkInput.csv','w') as _file:\n",
    "    _file.write(eLinkInputLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CSV_Files/CalibBlockInput.csv','w') as _file:\n",
    "    _file.write(calibInputLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CSV_Files/AlgoBlockInput.csv','w') as _file:\n",
    "    _file.write(algoInputLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CSV_Files/AlgoBlockOutput_Threshold_135.csv','w') as _file:\n",
    "    _file.write(algoOutputLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CSV_Files/FormattingBlockOutput_Threshold_135.csv','w') as _file:\n",
    "    _file.write(formattedDataLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CSV_Files/FormattingBlockOutput_Threshold_135_Truncated1.csv','w') as _file:\n",
    "    _file.write(formattedDataLines_Truncated1)\n",
    "\n",
    "with open('CSV_Files/FormattingBlockOutput_Threshold_135_Truncated2.csv','w') as _file:\n",
    "    _file.write(formattedDataLines_Truncated2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CSV_Files/Control_Module_Info.csv','w') as _file:\n",
    "    values = \"SUBDET, LAYER, MODULE\\n\"\n",
    "    values += \"%i, %i, %i\"%(subdet, layer, wafer)\n",
    "    values += \"\\n\\n\\n\"\n",
    "    values += str(eventTracker)\n",
    "    _file.write(values)\n",
    "    \n",
    "with open('CSV_Files/Control_Threshold_Levels.csv','w') as _file:\n",
    "    threshold_values = str(singleEvent.threshold_ADC.values.tolist())\n",
    "    threshold_values = threshold_values[1:-1]\n",
    "    line = ''\n",
    "    for i in range(48):\n",
    "        line += 'THRESHV_%i, '%i\n",
    "    line = line[:-2] + '\\n'\n",
    "    line += threshold_values + '\\n'\n",
    "    _file.write(line)\n",
    "\n",
    "    \n",
    "with open('CSV_Files/Control_Calibration_Values.csv','w') as _file:\n",
    "    calib_values = str(calibRegisters.tolist())\n",
    "    calib_values = calib_values[1:-1]\n",
    "    line = ''\n",
    "    for i in range(48):\n",
    "        line += 'CALV_%i, '%i\n",
    "    line = line[:-2] + '\\n'\n",
    "    line += calib_values + '\\n'\n",
    "    _file.write(line)\n",
    "\n",
    "with open('CSV_Files/Control_GeneralInformation.csv','w') as _file:\n",
    "    line = \"N_INPUT_LINKS, HDM\\n\"\n",
    "    line += '12, 1\\n'\n",
    "    _file.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"FormattingBlockOutput_Threshold_135\"\n",
    "inputFileName = \"CSV_Files/%s.csv\"%fileName\n",
    "inputFileNameTruncate1 = \"CSV_Files/%s_Truncated1.csv\"%fileName\n",
    "inputFileNameTruncate2 = \"CSV_Files/%s_Truncated2.csv\"%fileName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bufferdf = pd.read_csv(inputFileName,index_col='BC',skipinitialspace=True)\n",
    "Bufferdf_1 = pd.read_csv(inputFileNameTruncate1,index_col='BC',skipinitialspace=True)\n",
    "Bufferdf_2 = pd.read_csv(inputFileNameTruncate2,index_col='BC',skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "totalBufferSize = 840 ### in 16-bit wordss\n",
    "\n",
    "def getBufferOutputs(nOutputLinks, nBitsPerLink=32, maxLatency=12):\n",
    "\n",
    "    T2 = maxLatency*nOutputLinks*2\n",
    "    T1 = T2 - 25 ###max data size, 25 16-bit words\n",
    "\n",
    "    BufferContents = \"\"\n",
    "\n",
    "    line = \"BC, BufferSize, CurrentDataSize, T1, T2, Truncated1word, Truncated2words\"\n",
    "    for i in range(nOutputLinks):\n",
    "        line += \", eLink_%i\"%i\n",
    "    line += \"\\n\"\n",
    "\n",
    "\n",
    "    for BC in Bufferdf.index:\n",
    "        currentBXData = Bufferdf.loc[BC].DATA\n",
    "        trun1 = False\n",
    "        trun2 = False\n",
    "        bufferSize = len(BufferContents)/16\n",
    "        currentDataSize = len(currentBXData)/16\n",
    "    #     print (bufferSize, currentDataSize)\n",
    "    #     print (BufferContents)\n",
    "        if (bufferSize + currentDataSize)>T2:\n",
    "            currentBXData = Bufferdf_1.loc[BC].DATA        \n",
    "            trun1 = True\n",
    "        elif (len(BufferContents)/16)>T1:\n",
    "            currentBXData = Bufferdf_2.loc[BC].DATA\n",
    "            trun2 = True\n",
    "        else:\n",
    "            BufferContents += Bufferdf.loc[BC].DATA\n",
    "\n",
    "        line += \"%i, %i, %i, %i, %i, %i, %i, \"%(BC, bufferSize, currentDataSize, T1, T2, trun1, trun2)\n",
    "\n",
    "        buffers = []\n",
    "        for i in range(nOutputLinks):\n",
    "            linkData = BufferContents[:nBitsPerLink]\n",
    "            BufferContents = BufferContents[nBitsPerLink:]\n",
    "            nBits = len(linkData)\n",
    "            if nBits<nBitsPerLink:\n",
    "                linkData = '0'*(nBitsPerLink-nBits) + linkData\n",
    "            dataHex = format(int(linkData,2), '#0%ix'%(len(linkData)/4+2))\n",
    "            buffers.append(format(int(linkData,2), '#0%ix'%(len(linkData)/4+2)))\n",
    "            line += \"%s, \"%dataHex\n",
    "        line = line[:-2]+\"\\n\"\n",
    "    #    print (buffers, len(BufferContents))\n",
    "    return line\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBitsPerLink = 32\n",
    "maxLatency = 12\n",
    "\n",
    "for nLinks in range(2,12):\n",
    "    l = getBufferOutputs(nLinks)\n",
    "    \n",
    "    with open(\"CSV_Files/BufferOutput_Threshold_135_outputLinks_%i.csv\"%nLinks,\"w\") as _file:\n",
    "        _file.write(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
